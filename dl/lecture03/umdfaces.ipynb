{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Landmarks\n",
    "\n",
    "Using a subset of [UMD Faces](http://umdfaces.io) database to train a face landmarks predicting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import PIL.Image\n",
    "from imageio import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import defaults\n",
    "from fastai.vision import open_image\n",
    "from fastai.callbacks import (\n",
    "    EarlyStoppingCallback, \n",
    "    SaveModelCallback, \n",
    "    ReduceLROnPlateauCallback,\n",
    "    CSVLogger)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "DEVICE = torch.device('cuda:1')\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "defaults.device = DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset First Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.home()/'data'/'umdfaces'/'batch3'\n",
    "META = ROOT/'umdfaces_batch3_ultraface.csv'\n",
    "NUM_LANDMARKS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(META)\n",
    "meta.columns = meta.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = meta.columns\n",
    "file_cols = ['subject_id', 'file']\n",
    "face_cols = cols[cols.str.startswith('face')].tolist()\n",
    "x_cols = cols[cols.str.startswith('p') & cols.str.endswith('x')].tolist()\n",
    "y_cols = cols[cols.str.startswith('p') & cols.str.endswith('y')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_df = meta[file_cols + face_cols + x_cols + y_cols]\n",
    "faces_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(i, ax=None):\n",
    "    global faces_df, ROOT\n",
    "    r = faces_df.loc[i]\n",
    "    img = imread(ROOT/r.file)\n",
    "    x_pts = [r[k] for k in r.keys() if k[0] == 'p' and k[-1] == 'x']\n",
    "    y_pts = [r[k] for k in r.keys() if k[0] == 'p' and k[-1] == 'y']\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    rc = Rectangle(xy=(r.face_x, r.face_y), \n",
    "                   width=r.face_width, height=r.face_height,\n",
    "                   edgecolor='red', fill=False, lw=5)\n",
    "    ax.imshow(img)\n",
    "    ax.scatter(x_pts, y_pts, edgecolor='white', color='lightgreen', alpha=0.8)    \n",
    "    ax.add_patch(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_grid(n=3):\n",
    "    global faces_df\n",
    "    f, axes = plt.subplots(n, n, figsize=(12, 12))\n",
    "    indicies = np.random.choice(len(faces_df), n ** 2, replace=False)\n",
    "    for i, ax in zip(indicies, axes.flat):\n",
    "        show(i, ax=ax)\n",
    "        ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it seems that each sample includes (at least) one human in various poses with various backgrounds. Therefore, our first goal is to convert this dataset into a more suitable format before we processed with training the model. The most straightforward way to do so is to _crop_ the faces only and save them into smaller files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_face_landmarks_dataset(\n",
    "    root: Path,\n",
    "    faces_info: pd.DataFrame,\n",
    "    output: Path\n",
    "):\n",
    "    if output.exists():\n",
    "        print(f'The data is already prepared. Reading from folder: {output}')\n",
    "        images = [str(x) for x in read_ordered_files(output, '*.jpeg')]\n",
    "        points = [str(x) for x in read_ordered_files(output, '*.txt')]\n",
    "        if not images or not points:\n",
    "            print('Warning: no files in output folder! Delete the folder and try again')\n",
    "        data = pd.DataFrame({'image': images, 'points': points})\n",
    "        \n",
    "    else:\n",
    "        output.mkdir(parents=True)\n",
    "        print(f'Saving output into folder: {output}')\n",
    "        cols = faces_info.columns\n",
    "        records = [{\n",
    "            'subject_id': r.subject_id,\n",
    "            'input_path': root/r.file,\n",
    "            'output_image': output/f'{i}.jpeg',\n",
    "            'output_points': output/f'{i}.txt',\n",
    "            'x_pos': [r[k] for k in r.keys() if k[0] == 'p' and k[-1] == 'x'],\n",
    "            'y_pos': [r[k] for k in r.keys() if k[0] == 'p' and k[-1] == 'y'],\n",
    "            'face': (r.face_x, r.face_y, r.face_width, r.face_height)\n",
    "        } for i, r in faces_info.iterrows()]\n",
    "\n",
    "        print(f'Number of records to process: {len(records)}')\n",
    "        with Pool() as pool:\n",
    "            results = pool.map(crop_and_save, records)\n",
    "        data = pd.DataFrame(results)\n",
    "    \n",
    "    data['order'] = data.image.map(lambda s: int(Path(s).stem))\n",
    "    data.sort_values(by='order', inplace=True)\n",
    "    return data\n",
    "        \n",
    "    \n",
    "def read_ordered_files(path, pattern):\n",
    "    return list(sorted([fn for fn in path.glob(pattern)], key=lambda filename: int(filename.stem)))    \n",
    "\n",
    "\n",
    "def to_centered(xs, ys, w, h):\n",
    "    return 2*xs/w - 1, 2*ys/h - 1\n",
    "\n",
    "\n",
    "def to_absolute(xs, ys, w, h):\n",
    "    return w*(xs + 1)/2., h*(ys + 1)/2. \n",
    "\n",
    "    \n",
    "def crop_and_save(record):\n",
    "    x, y, w, h = record['face']\n",
    "    img = PIL.Image.open(record['input_path'])\n",
    "    cropped = img.crop(box=(x, y, x+w, y+h))\n",
    "    x_pos, y_pos = [np.array(record[k]) for k in ('x_pos', 'y_pos')]\n",
    "    x_pos, y_pos = to_centered(x_pos - x, y_pos - y, w, h)\n",
    "    cropped.save(record['output_image'], format='jpeg')\n",
    "    np.savetxt(record['output_points'], np.c_[x_pos, y_pos], fmt='%.4f', delimiter=',')\n",
    "    return {'image': str(record['output_image']), 'points': str(record['output_points'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_df = create_face_landmarks_dataset(ROOT, faces_df, ROOT.parent/'prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(df, i, ax=None):\n",
    "    record = df.loc[i]\n",
    "    show_image(record.image, record.points, create_axis(ax))\n",
    "\n",
    "    \n",
    "def create_axis(ax=None, size=6):\n",
    "    if not ax:\n",
    "        if isinstance(size, int):\n",
    "            size = (size, size)\n",
    "        f, ax = plt.subplots(1, 1, figsize=size)\n",
    "    return ax\n",
    "    \n",
    "    \n",
    "def show_image(image, points, ax):\n",
    "    if isinstance(image, str):\n",
    "        image = imread(image)\n",
    "    if isinstance(points, str):\n",
    "        points = np.loadtxt(points, delimiter=',')\n",
    "    points = points.reshape(NUM_LANDMARKS//2, 2)\n",
    "    h, w = image.shape[:2]\n",
    "    xs, ys = to_absolute(points[:, 0], points[:, 1], w, h)\n",
    "    ax.imshow(image)\n",
    "    ax.scatter(xs, ys, edgecolor='white', color='lightgreen', alpha=0.8)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    \n",
    "def show_grid(df, n=3):\n",
    "    f, axes = plt.subplots(n, n, figsize=(10, 10))\n",
    "    indicies = np.random.choice(len(df), n ** 2, replace=False)\n",
    "    for i, ax in zip(indicies, axes.flat):\n",
    "        show(df, i, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grid(landmarks_df, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarks(Dataset):\n",
    "    \n",
    "    def __init__(self, data, indicies=None, transforms=None):\n",
    "        if indicies is not None:\n",
    "            data = data.loc[indicies]\n",
    "        \n",
    "        self.images = [str(x) for x in data.image]\n",
    "        self.points = [str(x) for x in data.points]\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        img = imread(self.images[item])\n",
    "        pts = np.loadtxt(self.points[item], delimiter=',')\n",
    "        cat = np.r_[pts[:, 0], pts[:, 1]]\n",
    "        if self.transforms is not None:\n",
    "            img, cat = self.transforms(img, cat)\n",
    "        return img, cat\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def show(self, i):\n",
    "        show_image(self.images[i], self.points[i], create_axis(size=4))\n",
    "\n",
    "    @property\n",
    "    def c(self):\n",
    "        return NUM_LANDMARKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_df = create_face_landmarks_dataset(ROOT, faces_df, ROOT.parent/'prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(landmarks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_idx, val_idx = train_test_split(np.arange(n), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = FaceLandmarks(landmarks_df, indicies=trn_idx)\n",
    "val_ds = FaceLandmarks(landmarks_df, indicies=val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds.show(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial():\n",
    "    return np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize:\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.size = (size, size) if isinstance(size, int) else size\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        return cv.resize(image, self.size, cv.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rotate:\n",
    "    \n",
    "    def __init__(self, angle=5):\n",
    "        self.minmax = (-angle, angle) if isinstance(angle, int) else angle\n",
    "    \n",
    "    def __call__(self, image, target=None):\n",
    "        h, w = image.shape[:2]\n",
    "        angle = np.random.uniform(*self.minmax)\n",
    "        m = cv.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "        image = cv.warpAffine(image, m, (w, h))\n",
    "        \n",
    "        if target is not None:\n",
    "            new_target = np.copy(target)\n",
    "            n = target.shape[0] // 2\n",
    "            for i in range(n):\n",
    "                new_target[i] = m[0][0]*target[i] + m[0][1]*target[i + n]\n",
    "                new_target[i + n] = m[1][0]*target[i] + m[1][1]*target[i + n]\n",
    "            target = new_target\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shift:\n",
    "    \n",
    "    def __init__(self, shift=0.01):\n",
    "        self.minmax = (shift, shift) if isinstance(shift, float) else shift\n",
    "    \n",
    "    def __call__(self, image, target=None):\n",
    "        h, w = image.shape[:2]\n",
    "        sx, sy  = self.minmax\n",
    "        shift_x = np.random.randint(-w*sx, w*sx)\n",
    "        shift_y = np.random.randint(-h*sy, h*sy)\n",
    "        m = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "        image = cv.warpAffine(image, m, (w, h))\n",
    "        \n",
    "        if target is not None:\n",
    "            new_target = np.copy(target)\n",
    "            half = target.shape[0] // 2\n",
    "            last = target.shape[0]\n",
    "            new_target[0:half] = target[0:half] + shift_x/(w/2)\n",
    "            new_target[half:last] = target[half:last] + shift_y/(h/2)\n",
    "            target = new_target\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_flip(image, target=None):\n",
    "    if target is not None:\n",
    "        new_target = np.copy(target)\n",
    "        half = target.shape[0] // 2\n",
    "        new_target[0:half] *= -1\n",
    "        target = new_target\n",
    "    \n",
    "    return np.fliplr(image), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeIllumination:\n",
    "    \n",
    "    def __init__(self, min_alpha=0.8, max_alpha=1.1, delta=0.8):\n",
    "        self.min_alpha = min_alpha\n",
    "        self.max_alpha = max_alpha\n",
    "        self.delta = delta\n",
    "        \n",
    "    def __call__(self, image, target=None):\n",
    "        alpha = np.random.uniform(self.min_alpha, self.max_alpha)\n",
    "        mean = np.mean(image)\n",
    "        image = self.delta*image + (1 - self.delta)*mean\n",
    "        image *= alpha\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contiguous(image):\n",
    "    return np.ascontiguousarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_channels(image):\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_xy_tensors(image, target):\n",
    "    return (\n",
    "        torch.FloatTensor(image).permute(2, 0, 1),\n",
    "        torch.FloatTensor(target)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomTargetCompose:\n",
    "    \"\"\"Similar to transforms.Compose but optionally passes an additional \n",
    "    `target` parameter into transformation callables and applies \n",
    "    transformations randomly.\n",
    "    \"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __call__(self, image, target=None):\n",
    "        for t in self.transforms:\n",
    "            if isinstance(t, tuple):\n",
    "                rand, t = t\n",
    "                if binomial() > rand:\n",
    "                    continue\n",
    "            params = signature(t).parameters\n",
    "            if 'target' in params:\n",
    "                image, target = t(image, target)\n",
    "            else:\n",
    "                image = t(image)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = RandomTargetCompose([\n",
    "    (1.0, Rotate(angle=(-10, 10))),\n",
    "    (1.0, Shift(shift=0.05)),\n",
    "    (0.8, ChangeIllumination()),\n",
    "    (0.5, horizontal_flip),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = FaceLandmarks(landmarks_df, indicies=trn_idx, transforms=aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img, test_pts = trn_ds[0]\n",
    "h, w = test_img.shape[:2]\n",
    "n = len(test_pts)\n",
    "xs, ys = test_pts[:n//2], test_pts[n//2:]\n",
    "xs = w*(xs + 1)/2\n",
    "ys = h*(ys + 1)/2\n",
    "f, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.imshow(test_img.astype('uint8'))\n",
    "ax.scatter(xs, ys)\n",
    "print(test_img.shape)\n",
    "print(test_pts.shape)\n",
    "print('Range:', test_img.min(), test_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import Learner, DatasetType, to_np\n",
    "from fastai.vision import ImageDataBunch, imagenet_stats, create_cnn, imagenet_stats\n",
    "from torchvision import models\n",
    "from torchvision.transforms.functional import to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_aug = RandomTargetCompose([\n",
    "    Resize(224),\n",
    "    (0.5, Rotate(angle=(-15, 10))),\n",
    "    (0.5, Shift(shift=0.05)),\n",
    "    (0.5, ChangeIllumination()),\n",
    "    (0.5, horizontal_flip),\n",
    "    expand_channels,\n",
    "    contiguous,\n",
    "    to_xy_tensors,\n",
    "    T.Normalize(*imagenet_stats)\n",
    "])\n",
    "\n",
    "val_aug = RandomTargetCompose([\n",
    "    Resize(224),\n",
    "    expand_channels,\n",
    "    contiguous,\n",
    "    to_xy_tensors,\n",
    "    T.Normalize(*imagenet_stats)\n",
    "])\n",
    "\n",
    "trn_ds = FaceLandmarks(landmarks_df, indicies=trn_idx, transforms=trn_aug)\n",
    "val_ds = FaceLandmarks(landmarks_df, indicies=val_idx, transforms=val_aug)\n",
    "bunch = ImageDataBunch.create(trn_ds, val_ds, bs=64, num_workers=12)\n",
    "bunch.train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ROOT.parent/'tmp'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(bunch, models.resnet50, path=path, loss_func=F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, i, j=None):\n",
    "    model.train(False)\n",
    "    if j is not None:\n",
    "        j = max(j, i + 1)\n",
    "        batch = torch.stack([dataset[idx][0] for idx in range(i, j)])\n",
    "    else:\n",
    "        batch = dataset[i][0][None]\n",
    "    preds = model(batch.to(DEVICE))\n",
    "    model.train(True)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, dataset, i, j=None):\n",
    "    batch = predict(model, dataset, i, j)\n",
    "    n = int(math.sqrt(j - i))\n",
    "    m = (j - i) // n\n",
    "    images = [imread(dataset.images[idx]) for idx in range(i, j)]\n",
    "    f, axes = plt.subplots(n, m, figsize=(10, 10))\n",
    "    for img, pts, ax in zip(images, to_np(batch), axes.flat):\n",
    "        h, w = img.shape[:2]\n",
    "        xs, ys = pts[:NUM_LANDMARKS//2], pts[NUM_LANDMARKS//2:]\n",
    "        xs = w*(xs + 1)/2.\n",
    "        ys = h*(ys + 1)/2.\n",
    "        ax.imshow(img)\n",
    "        ax.scatter(xs, ys, color='lightgreen', edgecolor='white', alpha=0.8, s=30)\n",
    "        ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [\n",
    "    EarlyStoppingCallback(learn, patience=3),\n",
    "    Save]\n",
    "learn.fit_one_cycle(10, max_lr=5e-3, wd=1e-2, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(learn.model, val_ds, 0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-06\n",
    "cb = [EarlyStoppingCallback(learn, patience=5)]\n",
    "learn.fit_one_cycle(20, max_lr=[lr/10, lr/3, lr], wd=1e-4, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(learn.model, val_ds, 32, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = imread(val_ds.images[0])\n",
    "# pts = np.loadtxt(val_ds.points[0], delimiter=',')\n",
    "# h, w = img.shape[:2]\n",
    "# xs, ys = pts[:, 0], pts[:, 1]\n",
    "# xs, ys = to_absolute(xs, ys, w, h)\n",
    "# pts1 = np.float32([[0,0],[w,0],[0, h],[w,h]])\n",
    "# pts2 = np.float32([[0,0],[w,0],[0,h],[w,h/2]])\n",
    "# m = cv.getPerspectiveTransform(pts1,pts2)\n",
    "# img = cv.warpPerspective(img, m, img.shape[:2])\n",
    "# for i in range(NUM_LANDMARKS//2):\n",
    "#     xs[i] = (m[0][0]*xs[i] + m[0][1]*ys[i] + m[0][2])/m[]\n",
    "#     ys[i] = m[1][0]*xs[i] + m[1][1]*ys[i] + m[1][2]\n",
    "# f, ax = plt.subplots(1, 1)\n",
    "# ax.imshow(img)\n",
    "# ax.scatter(xs, ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
